---
title:  "AI 커뮤니케이션의 미래 발견: ChatGPT" 

categories:
  - AI Core Projects
tags:
  - [ChatGPT]

toc: true
toc_sticky: true

date: 2023-03-14
last_modified_at: 2023-03-14
---

<br/> 

### ChatGPT란

챗 GPT (= Generative Pre-trained Model)

혁신적인 대화형 AI 언어 모델로 Generative 생성형 AI 중 하나이다. 단순한 일상 대화를 주고 받기 보다는 **대화를 통한 세부 정보 획득**이 목적이다. 

챗 GPT에서는 일반적인 검색 기능을 넘어서, 미리 검색해서 학습한 인공지능이 더 상세한 문장으로 풀어서 답변을 해준다. 이를 통해 훨씬 빠르고 간편한 접근이 가능해지면서 구글의 긴장감은 고조화 되었고, 최근 “코드 레드(심각한 위기 상황)”까지 발령했다. 

새롭게 등장한 이 챗봇 기술이 기존의 검색 엔진을 대체할 것이라는 의견도 제기되고 있다. 

**언어 모델** : 데이터의 패턴을 학습해서 다음 순서의 단어를 예측하는 것 

- 자연어 텍스트를 처리하고 생성하도록 훈련된 기계학습 모델
- token 토큰 : 인공지능이 이해하는 최소의 언어 단위, 분리된 음절

![image](https://user-images.githubusercontent.com/86834982/224891856-8e0e13fa-2ede-45c5-9289-53c3b76bba60.png){: width="550px"}  


<br/> 
### **Understanding AI vs. Generative AI**

- Understanding AI : 데이터의 의미를 분석하고 이해 (구글 스마트 스피커 등)
- Generative AI : 새로운 컨텐츠를 생성 (음악, 그림, 챗봇 등)
    
    -> 여기서 구글의 트랜스포머가 큰 기여를 했다고 볼 수 있다
    
    -> 사람들이 더 만족하는 결과를 이끌었기 때문에 더 관심도 증가 (향후 6-7년)
    

![image](https://user-images.githubusercontent.com/86834982/224891881-114e1cd6-2f76-4dde-b455-5ba1a9533893.png){: width="550px"}  


<br/> 
### Transformer (Bert와 GPT)

![image](https://user-images.githubusercontent.com/86834982/224891934-31243a02-a91b-437f-bf3f-6bca60fb911a.png){: width="550px"}  


<br/> 
### GPT의 버전

GPT-1, 2, 3으로 버전이 증가함에 따라 parameter의 갯수도 기하급수적으로 상승 

-> 인간에 비해 적은 갯수로 인간과 같은 텍스트 응답을 생성 

-> 한 번 학습시키는데 50억 정도 들어간다고 한다 ,, 

![image](https://user-images.githubusercontent.com/86834982/224891948-b6c6f5b4-a456-477f-9a20-0f2df040d4d9.png){: width="550px"}  


<br/> 
### ChatGPTBing (ChatGPT + MS Bing)

챗 GPT 3.5를 기반으로 하는 또 다른 대화형 인공지능 서비스이다. 

마이크로소프트는 챗 GPT의 개발사인 OpenAI와 결합하여 기존의 챗 GPT를 오피스 제품과 검색엔진 Bing에 적용하여 발표했다. 또한 애저(Azure)와도 결합하여 오픈 AI에 클라우드 서비스를 단독 제공할 것이라고 전했다. 

![image](https://user-images.githubusercontent.com/86834982/224892015-a9138657-6b20-4f2f-9731-a7d29b3f15e6.png){: width="550px"}  

-> 한계점

- 보고서/논문 작성 도움을 받을 수는 있지만 너무 의지하면 안될 것
- 2021년도까지의 데이터가 학습되어 있기 때문에 이후의 정보는 알 수 없음.


<br/> 
### LLaMA

Open and Efficient Foundation Language Model 

이번에 페이스북(메타 AI)에서 발표한 새로운 언어 모델이다. 

- 파라미터 수와 모델의 크기를 줄였음에도 GPT3보다 성능이 좋다.
- GPT3가 가진 토큰 (3000억) 보다 많은 1조개의 토큰을 가진 모델
- 결론 : **데이터가 많으면 많을수록** 도움이 된다.

-> 해당 논문의 결과를 통해 유추해볼 수 있는 것은 양질의 데이터가 매우 중요한 조건이며 앞으로 프로젝트를 할 때도 데이터를 어떻게 가져오고, 정제해서 사용하는지에 초점을 두는 것이 중요할 것 같다!

[https://github.com/facebookresearch/llama](https://github.com/facebookresearch/llama)




<br/><br/>
[맨 위로 이동하기](#){: .btn .btn--primary }{: .align-right}
