---
title:  "[PBL2]  ë’·í†µìˆ˜ ì¸ì‹ ëª¨ë¸ êµ¬í˜„í•´ë³´ê¸°" 

categories:
  - AI Core Project
tags:
  - [project, yolov5, classification]

toc: true
toc_sticky: true

date: 2022-11-29
last_modified_at: 2022-11-29
---

<br/> 
ë‹¹ê·¼ ì´ë¯¸ì§€ê°€ ì‚¬ëŒë“¤ ë’·í†µìˆ˜ë„ ê°€ë¦¬ë©´ì„œ ì§€ì €ë¶„í•˜ë‹¤ëŠ” í”¼ë“œë°±ì„ ë°›ì•„ì„œ ì´ë¥¼ í•´ê²°í•´ë³´ê¸° ìœ„í•´ ê°„ë‹¨í•œ ì•í†µìˆ˜/ë’·í†µìˆ˜ classification ëª¨ë¸ì„ êµ¬í˜„í•´ë´¤ë‹¤. 

<br/> 
### Data Preprocessing

í•„ìš”í•œ ëª¨ë“ˆ ì „ë¶€ ë¶ˆëŸ¬ì˜¤ê¸°

```python
# í•„ìš”í•œ ëª¨ë“ˆ ë¶ˆëŸ¬ì˜¤ê¸° 
import os 
import shutil
import math
import time
import copy
import random
import torch
import torchvision.transforms as transforms
from torchvision import models
from torchvision.datasets import ImageFolder
from torch.utils.data import DataLoader
from torch.optim import lr_scheduler
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
from PIL import Image 
import matplotlib.pyplot as plt
import matplotlib.image as mpimg
```
<br/> 
ë°ì´í„° ë¶„í• í•˜ê¸° : train/val/test ë°ì´í„°ë¥¼ ê°ê° 6:2:2 ë¹„ìœ¨ë¡œ ë¶„ë°° 

```python
# ë°ì´í„°ì…‹ ë¶„í• í•˜ê¸° 
dataset_dir = './dataset'
class_list = os.listdir(dataset_dir)  # ['backHead', 'face']

splitted_dataset_dir = './splitted'
try:
    os.mkdir(splitted_dataset_dir)
except:
    shutil.rmtree('./splitted')
    os.mkdir(splitted_dataset_dir)

train_dir = os.path.join(splitted_dataset_dir, 'train')
os.mkdir(train_dir)
validation_dir = os.path.join(splitted_dataset_dir, 'val')
os.mkdir(validation_dir)
test_dir = os.path.join(splitted_dataset_dir, 'test')
os.mkdir(test_dir)

for cls in class_list:
    os.mkdir(os.path.join(train_dir, cls))
    os.mkdir(os.path.join(validation_dir, cls))
    os.mkdir(os.path.join(test_dir, cls))

for cls in class_list:
    path = os.path.join(dataset_dir, cls)
    fnames = os.listdir(path)
    random.shuffle(fnames)
    
    train_size = math.floor(len(fnames) * 0.6)
    validation_size = math.floor(len(fnames)*0.2)
    test_size = math.floor(len(fnames)*0.2)
    
    train_fnames = fnames[:train_size]
    print("Train size(",cls,"): ", len(train_fnames))
    for fname in train_fnames:
        src = os.path.join(path, fname)
        dst = os.path.join(os.path.join(train_dir, cls), fname)
        shutil.copyfile(src, dst)
        
    validation_fnames = fnames[train_size:(validation_size + train_size)]
    print("Validation size(",cls,"): ", len(validation_fnames))
    for fname in validation_fnames:
        src = os.path.join(path, fname)
        dst = os.path.join(os.path.join(validation_dir, cls), fname)
        shutil.copyfile(src, dst)
        
    test_fnames = fnames[(train_size+validation_size):(validation_size + train_size +test_size)]

    print("Test size(",cls,"): ", len(test_fnames))
    for fname in test_fnames:
        src = os.path.join(path, fname)
        dst = os.path.join(os.path.join(test_dir, cls), fname)
        shutil.copyfile(src, dst)
```

<br/> <br/> 
### Model Training

ë¨¼ì € í•™ìŠµì„ í•˜ê¸° ìœ„í•œ hyperparameter ì„ íƒ 

```python
USE_CUDA = torch.cuda.is_available()
DEVICE = torch.device("cuda" if USE_CUDA else "cpu")
BATCH_SIZE = 256 
EPOCH = 20
```
<br/> 
í•™ìŠµ ë°ì´í„° ì „ì²˜ë¦¬ ë° ë¡œë“œí•˜ê¸° 

```python
data_transforms = {
    'train': transforms.Compose([transforms.Resize([64,64]), 
        transforms.RandomHorizontalFlip(), transforms.RandomVerticalFlip(),  
        transforms.RandomCrop(52), transforms.ToTensor(), 
        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]) ]),
    
    'val': transforms.Compose([transforms.Resize([64,64]),  
        transforms.RandomCrop(52), transforms.ToTensor(),
        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]) ])
}

data_dir = './splitted' 
image_datasets = {x: ImageFolder(root=os.path.join(data_dir, x), transform=data_transforms[x]) for x in ['train', 'val']} 
dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=BATCH_SIZE, shuffle=True, num_workers=4) for x in ['train', 'val']} 
dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}

class_names = image_datasets['train'].classes
```
<br/> 
í•™ìŠµì— ì‚¬ìš©í•  resnet ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸°

```python
resnet = models.resnet50(pretrained=True)  
num_ftrs = resnet.fc.in_features   
resnet.fc = nn.Linear(num_ftrs, 2) 
resnet = resnet.to(DEVICE)
 
criterion = nn.CrossEntropyLoss() 
optimizer_ft = optim.Adam(filter(lambda p: p.requires_grad, resnet.parameters()), lr=0.001)
 
exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)
```
<br/>
resnet ëª¨ë¸ì„ trainingí•˜ëŠ” í•¨ìˆ˜ 

```python
def train_resnet(model, criterion, optimizer, scheduler, num_epochs=25):

    best_model_wts = copy.deepcopy(model.state_dict())  
    best_acc = 0.0  
    
    for epoch in range(num_epochs):
        print('-------------- epoch {} ----------------'.format(epoch+1)) 
        since = time.time()                                     
        for phase in ['train', 'val']: 
            if phase == 'train': 
                model.train() 
            else:
                model.eval()     
 
            running_loss = 0.0  
            running_corrects = 0  
 
            
            for inputs, labels in dataloaders[phase]: 
                inputs = inputs.to(DEVICE)  
                labels = labels.to(DEVICE)  
                
                optimizer.zero_grad() 
                
                with torch.set_grad_enabled(phase == 'train'):  
                    outputs = model(inputs)  
                    _, preds = torch.max(outputs, 1) 
                    loss = criterion(outputs, labels)  
    
                    if phase == 'train':   
                        loss.backward()
                        optimizer.step()
 
                running_loss += loss.item() * inputs.size(0)  
                running_corrects += torch.sum(preds == labels.data)  
            if phase == 'train':  
                scheduler.step()
 
            epoch_loss = running_loss/dataset_sizes[phase]  
            epoch_acc = running_corrects.double()/dataset_sizes[phase]  
 
            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc)) 
 
          
            if phase == 'val' and epoch_acc > best_acc: 
                best_acc = epoch_acc
                best_model_wts = copy.deepcopy(model.state_dict())
 
        time_elapsed = time.time() - since  
        print('Completed in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))
    print('Best val Acc: {:4f}'.format(best_acc))
 
    model.load_state_dict(best_model_wts) 
    return model
```
<br/> 
ì‹¤ì œ training ì‹œí‚¤ëŠ” ì½”ë“œ 

```python
model_resnet50 = train_resnet(resnet, criterion, optimizer_ft, exp_lr_scheduler, num_epochs=EPOCH) 
torch.save(model_resnet50, 'resnet50.pt')
```

<br/> <br/> 
### Model Testing

ëª¨ë¸ í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•œ ë°ì´í„° ì „ì²˜ë¦¬ 

```python
transform_resNet = transforms.Compose([
        transforms.Resize([64,64]),  
        transforms.RandomCrop(52),  
        transforms.ToTensor(),
        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]) 
    ])
    
test_resNet = ImageFolder(root='./splitted/test', transform=transform_resNet) 
test_loader_resNet = torch.utils.data.DataLoader(test_resNet, batch_size=BATCH_SIZE, shuffle=True, num_workers=4)
```
<br/> 
ëª¨ë¸ testingí•˜ëŠ” í•¨ìˆ˜

```python
def evaluate(model, test_loader):
    model.eval()  
    test_loss = 0 
    correct = 0   
    
    with torch.no_grad(): 
        for data, target in test_loader:  
            data, target = data.to(DEVICE), target.to(DEVICE)  
            output = model(data) 
            
            test_loss += F.cross_entropy(output,target, reduction='sum').item() 
 
            
            pred = output.max(1, keepdim=True)[1]
            correct += pred.eq(target.view_as(pred)).sum().item() 
   
    test_loss /= len(test_loader.dataset) 
    test_accuracy = 100. * correct / len(test_loader.dataset) 
    return test_loss, test_accuracy
```
<br/> 
ëª¨ë¸ í…ŒìŠ¤íŠ¸ loss, accuracy ê°’ í™•ì¸í•˜ê¸°

```python
resnet50=torch.load('resnet50.pt') 
resnet50.eval()  
test_loss, test_accuracy = evaluate(resnet50, test_loader_resNet)
print('ResNet test acc:  ', test_accuracy)
```  
<br/> 
-> ëŒë ¤ë³¸ ê²°ê³¼ ìƒê°ë³´ë‹¤ ì •í™•ë„ê°€ ë†’ê²Œ ë‚˜ì™”ë‹¤

![image](https://user-images.githubusercontent.com/86834982/204511739-7d0891a5-7eb7-45c2-8892-577ed8bc5422.png){: width="85%" height="85%"}  

<br/> 
í•œ ì¥ì˜ ì´ë¯¸ì§€ë¥¼ ë„£ì–´ì„œ testí•˜ëŠ” ì½”ë“œ

```python
test_img = Image.open("ë„£ì„ ì´ë¯¸ì§€").convert('RGB')
plt.imshow(test_img)
plt.show()  # ì´ë¯¸ì§€ ë³´ê¸° 

test_resNet = transform_resNet(test_img)
test_resNet = test_resNet.unsqueeze(0)
test_resNet = test_resNet.to(DEVICE)

model = resnet50.eval()  
output = model(test_resNet)
index = output.data.cpu().numpy().argmax()
class_name = class_list[index]
print(class_name) # ë¶„ë¥˜í•œ output
```
<br/> 
-> ì–´ë–¤ ë¯¸ìš©ì‹¤ ê´‘ê³ ì—ì„œ ê°€ì ¸ì˜¨ ì‚¬ì§„ì„ ë„£ì–´ë´¤ëŠ”ë° ì˜ ëŒì•„ê°„ë‹¤ !

![image](https://user-images.githubusercontent.com/86834982/204511751-1920d7ca-b5d9-4d6a-8ee5-cfaa1d6a037f.png){: width="85%" height="85%"}   
 
  
   
<br/> 
### Result 

ìƒê°ë³´ë‹¤ ì„±ëŠ¥ì´ ì¢‹ê²Œ ë‚˜ì™€ì„œ ë°”ë¡œ ì˜ìƒì—ë„ ì ìš©ì‹œì¼œë´¤ë‹¤. 

ì €ë²ˆì£¼ í”„ë¡œì íŠ¸ íŒŒì¼ì— backhead ì˜µì…˜ì„ ì¶”ê°€í•´ì„œ ë’·í†µìˆ˜ê°€ ì•„ë‹ ë•Œë§Œ í‚¤ìœ„ ì´ë¯¸ì§€ë¥¼ ë„£ë„ë¡ ìˆ˜ì •í•œ ê²°ê³¼, ë’·í†µìˆ˜ë¥¼ ì˜ ì¸ì‹í•˜ê³  ì‚¬ì§„ì´ ë“¤ì–´ê°€ì§€ ì•Šì•˜ë‹¤!  

![image](https://user-images.githubusercontent.com/86834982/204511784-79d23dba-a95f-4546-9c3b-215ebebba178.png){: width="85%" height="85%"}  

<br/> 
ê¹”ë”í•˜ê²Œ ì˜ ê°€ë ¤ì§€ëŠ” ë“¯ í–ˆì§€ë§Œ ë¬¸ì œëŠ” ì–˜ê°€ ì´ì   ì•í†µìˆ˜ë„ í—·ê°ˆë ¤ í•˜ëŠ” ê²ƒ ê°™ë‹¤. ë§ˆìŠ¤í¬ ë‚€ ì–¼êµ´ì„ ë’·í†µìˆ˜ë¡œ ê°€ë” ì¸ì‹í•œë‹¤. 

![image](https://user-images.githubusercontent.com/86834982/204511762-9e347384-4700-4d37-ac32-bc3f3a6af6c6.png){: width="85%" height="85%"}  

<br/> 
ë‚´ê°€ ìƒê°í–ˆì„ ë•Œ ê°œì„ í•´ì•¼ í•  ì ë“¤ 

- ì• ì´ˆì— í•™ìŠµì‹œí‚¨ ë°ì´í„°ì…‹ì´ ë„ˆë¬´ ì ë‹¤. (ìµœì†Œ ì²œ ì¥)
- ë§ˆìŠ¤í¬ ì“´ ì–¼êµ´ ë°ì´í„° ì…‹ë„ ë„£ì—ˆì–´ì•¼ í•œë‹¤.
- ì—¬ì „íˆ ì´ë¯¸ì§€(í‚¤ìœ„) í¬ê¸°ê°€ ë„ˆë¬´ ì™”ë‹¤ê°”ë‹¤ ì •ì‹ ì—†ë‹¤.

<br/> 
ì´ë²ˆ í”„ë¡œì íŠ¸ ëŠë‚€ ì 

ë‚´ ì²« ë”¥ëŸ¬ë‹ í”„ë¡œì íŠ¸ì—¬ì„œ ì‚¬ì‹¤ ê²°ê³¼ë„ ëª» ë½‘ëŠ”ê±° ì•„ë‹Œì§€ ê±±ì •ì´ ë§ì•˜ëŠ”ë° ê·¸ë˜ë„ ë°œí‘œëŠ” í•  ìˆ˜ëŠ” ìˆì„ ì •ë„ë¡œ ë§ˆë¬´ë¦¬ë¼ì„œ ë‹¤í–‰ì´ë‹¤. í”Œì  ê¸°ê°„ì´ í•œ ë‹¬ë³´ë‹¤ ì¢€ ë” ê¸¸ì—ˆìœ¼ë©´ ë” ì¢‹ì€ ê²°ê³¼ë¥¼ ë§Œë“¤ ìˆ˜ ìˆì—ˆì„ê±° ê°™ì€ë° ì•„ì‰½ë‹¤. ì´ë²ˆ ë°©í•™ ë•Œ ë”¥ëŸ¬ë‹ ê³µë¶€ë„ í•  ê²¸ ë‚¨ì€ ë¶€ë¶„ë“¤ì„ ì¢€ ë” ê³ ì³ë´ì•¼ê² ë‹¤. ğŸ˜­


<br/><br/>
[ë§¨ ìœ„ë¡œ ì´ë™í•˜ê¸°](#){: .btn .btn--primary }{: .align-right}
