---
title:  "일반인 얼굴에 당근이미지 대치" 

categories:
  - AI Core Projects
tags:
  - [project, facedetection]

toc: true
toc_sticky: true

date: 2022-11-27
last_modified_at: 2022-11-27
---


<br/> 
이번주에 한 것들 

1. 가장 큰  bounding box (= 주인공) 구하기
2. 주인공을 제외한 나머지 얼굴에 당근 이미지 씌우기 


<br/> 
### 출력 결과

당근 씌우기 성공 !!

![image](https://user-images.githubusercontent.com/86834982/204151594-e925fe95-dcf1-478c-9dff-a888bb7e21a1.png){: width="300px"}  



<br/> 
### 1. 가장 큰 bounding box (= 주인공) 구하기

먼저 detect.py를 보면, 이미 xyxy에 bounding box 좌표를 저장해서 사용하고 있다. 

`for *xyxy, conf, cls in reversed(det):`

어떻게 저장을 하는지 확인을 해본 결과, 아래와 같이 tensor 자료형에 저장하고 있었다. 

![image](https://user-images.githubusercontent.com/86834982/204151593-1a7aaebd-d7c0-4d2c-bb30-580a306f24b7.png){: width="400px"}  

<br/> 
따라서 이미지 연산을 위해 xyxy를 numpy 배열로 바꾸어 따로 저장한 후, 넓이를 계산해서 가장 큰 bounding box를 구한다. 

```python
# Get max_bbox
count, max_vol, max_idx = 0, 0.0, 0
max_box = np.zeros((1, 4), dtype = float)

for *xyxy, conf, cls in reversed(det):
		res, coor = [],[]
		# xyxy to numpy
		for i in xyxy:
		coor.append(i.numpy())
		res.append(coor)
		res = np.array(res, dtype=float)
		# 넓이 계산하기 
		vol = (res[0,2] - res[0,0]) * (res[0,3] - res[0,1])
		label = f'{names[int(cls)]} {conf:.2f}'
		if opt.heads or opt.person:
				if 'head' in label and opt.heads:
						if vol > max_vol and opt.heads :
								max_vol = vol    # 가장 큰 바운딩 박스 넓이 저장
	              max_idx = count  # 가장 큰 바운딩 박스 인덱스 저장
                max_box = res    # 가장 큰 바운딩 박스 저장 
    count+=1
```


<br/> <br/> 
### 2. 주인공을 제외한 나머지 얼굴에 당근 이미지 씌우기

아래 plot_one_box 부분에서 바운딩 박스를 그리고 있는데, 그 위에 불러온 당근 이미지를 씌워주면 된다. 단, 미리 당근 이미지를 불러와서 해당 박스 크기에 맞게 resizing을 해주어야 한다. 

```python
# get image to add
img = cv2.imread("bunny.png")

# Write results
count = 0
for *xyxy, conf, cls in reversed(det):
		res, coor = [],[]
    # xyxy to numpy
    for i in xyxy:
        coor.append(i.numpy())
    res.append(coor)
    res = np.array(res, dtype=int)
		# 바운딩 박스 크기로 당근 이미지 resize 
    img_r = cv2.resize(img, (res[0,2] - res[0,0], res[0,3] - res[0,1]))
                    
if save_img or view_img:  # Add bbox to image
   label = f'{names[int(cls)]} {conf:.2f}'
   if opt.heads or opt.person:
			# max bounding box가 아닌 경우 
      if 'head' in label and opt.heads and count!= max_idx: 
          plot_one_box(xyxy, im0, label=label, color=colors[int(cls)], line_thickness=3)
          # 원본 이미지의 바운딩 박스 부분에 당근 이미지 씌우기 !
					im0[res[0,1]:res[0,3], res[0,0]:res[0,2]] = img_r
```


<br/> <br/> 
### 피드백 및 문제점

- 당근 png 이미지 백그라운드가 투명하지 않고 검은색으로 출력됨
    
    이미지 뒷 배경 값을 null 값으로 받아오지 않고, 자동으로 값을 초기화하는 것 같다. opencv로 이미지를 불러올 때 초기화를 하는지, numpy 배열로 바꾸어 저장할 때 초기화를 하는지 뜯어봐야할듯. 생각해보면 이미지 값이 null이면 이미지 연산할 때 무조건 에러가 날텐데 이렇게 취약하게 코드를 짜놓았을리가 없긴해..
    
     -> 해결할 방법 찾아보기
    
- 측면 얼굴은 잘 인식이 되는지? 빠르게 지나가는 사람의 경우는 어떻게 할 것인지?
- 시간이 남는다면 deepface와 같은 다른 face detection 모델들도 돌려보기

<br/><br/>
[맨 위로 이동하기](#){: .btn .btn--primary }{: .align-right}
